\section{Background about Shake\label{sec:shake}}

Our solution to the issues raised in \S\ref{sec:challenges} starts with switching from \make{} to the Shake build system \cite{shake}. In this section we recap the key ideas behind Shake, and also describe some of the additional feature provided by Shake but not covered in the original paper. These features are of general use and all predate our efforts to replace the GHC build system.

\begin{figure}
\begin{lstlisting}
newtype Rule a = ...
    deriving (Monoid, Functor, Applicative, Monad)
newtype Action a = ...
    deriving (Functor, Applicative, Monad, MonadIO)

data ShakeOptions = ...
shakeOptions :: ShakeOptions

shake :: ShakeOptions -> Rules () -> IO ()
action :: Action a -> Rules ()

type ShakeValue a =
    (Show a, Typeable a, Eq a
    ,Hashable a, Binary a, NFData a)
data EqualCost = EqualCheap | EqualExpensive | NotEqual

class (ShakeValue key, ShakeValue value) =>
        Rule key value where
    storedValue :: ShakeOptions ->
        key -> IO (Maybe value)
    equalValue :: ShakeOptions ->
        key -> value -> value -> EqualCost

rule :: Rule key value =>
    (key -> Maybe (Action value)) -> Rules ()
apply :: Rule key value => [key] -> Action [value]
\end{lstlisting}
\todo{Include everything we use in the paper}
\caption{Shake generic API\label{fig:shake_generic_api}}
\end{figure}

\begin{figure}
\begin{lstlisting}
type FilePattern = String
(%>) :: FilePattern -> (FilePath -> Action ()) -> Rules ()
(?>) :: (FilePath -> Bool) -> (FilePath -> Action ()) -> Rules ()
want :: [FilePath] -> Rules ()
need :: [FilePath] -> Action ()
needed :: [FilePath] -> Action ()
\end{lstlisting}
\caption{Shake file-specific API\label{fig:shake_file_api}}
\end{figure}

\subsection{Introduction}

As an example of a small build system, let us compile a C file into an object file. We can write that in Shake with:

\begin{lstlisting}[numbers=left,xleftmargin=2em,framexleftmargin=1.5em]
module Main(main) where
import Development.Shake
import System.FilePath

main :: IO ()
main = shake shakeOptions $ do
    want ["foo.o"]

    "*.o" %> \out -> do
        let src = replaceExtension out "c"
        need [src]
        cmd "gcc -o" out "-c" src
\end{lstlisting}

Following the code from top to bottom:

\begin{description}
\item[Line 1] declares a Haskell module. Shake is a Haskell library, so all Shake build systems are written in Haskell and can make full use of other Haskell libraries and Haskell abstractions (functions, modules, packages, \lst'let' expressions etc).
\item[Line 2] imports the \lst'Development.Shake' module, which provides most of the functions and types in Shake. Some of the Shake API is given in Figures \ref{fig:shake_generic_api} and \ref{fig:shake_file_api}.
\item[Line 3] imports the \lst'System.FilePath' module, which in this example provides the \lst'replaceExtension' function.
\item[Lines 6] declares the \lst'main' function, which calls \lst'shake'. The \lst'shake' function takes some options (parallelism settings etc), along with a set of \lst'Rules', and executes the necessary rules.
\item[Line 7] calls \lst'want' to declare that after the build system has finished we would like the file \lst'foo.o' to be available and up-to-date.
\item[Line 9] defines a rule to build \lst'*.o' files, namely those which end with the extension \lst'.o'. The \lst'%>' operator produces a singleton set of \lst'Rules' which takes a pattern on the left, and an \lst'Action' on the right. The variable \lst'out' will be bound to the actual file being produced, namely \lst'foo.o' in this example.
\item[Line 10] computes the name of the source file, in our case \lst'src' will be \lst'foo.c'.
\item[Line 11] uses \lst'need' to ensure \lst'foo.c' has been built before continuing, and to introduce a dependency that if \lst'foo.c' changes then this rule will require rerunning.
\item[Line 12] uses the variable-arity function \lst'cmd' to execute the system command \lst'gcc' with appropriate arguments to produce \lst'out' from \lst'src'. Since the \lst'Action' type has an instance of \lst'MonadIO' we can do any \lst'IO' operation at this point.
\end{description}

On the first execution, this example will start running the \lst'*.o' rule to produce \lst'foo.o'. When execution gets to \lst'need [src]' this rule will stop and the rule for \lst'foo.c' will be be run. Shake provides a default rule for files that do not match any rules, which simply checks the file already exists. After completing this simple rule, Shake will resume running the \lst'*.o' rule, executing \lst'gcc' to build \lst'foo.o'.

If a similar build system was written in \make{}, \lst'gcc' would be rerun if either \lst'foo.o' did not exist, or if the modification time of \lst'foo.o' was earlier than that of \lst'foo.c'. In contrast, Shake will rerun \lst'gcc' if either file does not exist or changes modification time from when the rule was last run (or more generally, if either file changes contents, see \S\ref{sec:file-contents}). Shake achieves this result by storing the inputs and outputs after a rule completes in a per-project database, and rerunning a rule if anything has changed (and thus the result could be expected to change). Unlike \make{}, the Shake formulation of spotting differences is robust to changing the system time or extracting old files from backups.

\subsection{Post-use dependencies}

\S? of \cite{shake} postulates a number of invariants, and using the \prog{FSATrace} program these can now be checked at runtime. Shake has a \texttt{--lint} flag which also checks the current working directory does not change (a common mistake in a global build system, as the current working directory is a shared resource). It also checks that files do not change after they have been depended upon, that running a fresh build after a build completes will have no further effect, and that.

We also have a function \lst'needed', rather than \lst'need' that asserts that the result of performing \lst'need' does not cause the file to change. This is typically required to depend on files that have already been used, e.g. the header files have already been scanned, so if they were to build afresh that would be an error.

Most useful one is if two people whack the same output. Other thing is where doing all .hs files in a dir, and then you generate one. Should this go somewhere else? Perhaps in S5.




Looking at the body of the rule, we have tracked what happens if the .c file changes, but what if any headers that the .c file includes change? The program gcc takes a -M option that lets us save the dependencies to a file:

\begin{lstlisting}
let src = x -<.> "c"
need [src]
Stdout mk <- cmd "gcc -o" out "-M" "-c" src
need $ makefileDepends mk
\end{lstlisting}

We rely on an auxiliary \lst'makefileDepends' which parses a Makefile and returns all the dependencies \footnote{Using the \lst'parseMakefile' function in Shake we can define \lst'makefileDepends = concatMap snd . parseMakefile'.}. After finding all the dependencies we \lst'need' them, thus ensuring that if a header changes it will be rebuilt.

In fact, since Shake is a monadic build system, the \lst'need' will actually build them - a very useful feature and one that sets Shake apart. However, in this case if the header files are built after the execution of \lst'gcc' then the object file will be incorrect, so instead we can switch the final \lst'need' for \lst'needed'. This combines a \lst'need' which an assertion that the file does not change as a result of building.


\subsection{Order-only dependencies}

One dependency feature missing from the original Shake paper was order-only dependencies. An order-only dependency is one that must be built before continuing, but if the order-only dependency changes this rule does not need to rerun. A legitimate use of such a dependency is that an action might read any one of two files, and after the fact, can report which files it actually depended upon. Usually then a subset of these files will be added as explicit dependencies afterwards.

This pattern can be modelled in Shake using a rule whose key type is \lst'()' -- one that always compares equal, and the user defining a tag for the closure required, so it can be stored in the database. While workable, the pattern is not particularly reusable, so we instead provide a function that directly resets the dependency state.

Is this used? Add an example.


\subsection{Polymorphic dependencies}

While Shake can depend on files, it can also depend on other things, specifically Fig 1 is all about the core of Shake, while Fig 2 is about a wrapping for files. For example, we can define a rule that produces the version of gcc, allowing wrapping it easily.

\begin{lstlisting}
newtype GccVersion () deriving ...
instance Rule GccVersion String where
    storedValue _ _ = return Nothing
gccVersion = rule $ \(GccVersion _) -> Just $ do
    Stdout s <- cmd "gcc --version"
    return s
\end{lstlisting}

Now we can agument our rule by including:

\begin{lstlisting}
apply [GccVersion ()] :: Action [String]
\end{lstlisting}

Now, if the gcc version changes our rule will rebuild. To ensure this happens when required, our build system will necessarily run the gcc version command in each iteration. To simplify this pattern we wrap the common pattern up as an oracle:

\begin{lstlisting}
gccVersion <- addOracle $ \(GccVersion _) ->
    Stdout s <- cmd "gcc --version"
    return s

gccVersion $ GccVersion ()
\end{lstlisting}

Now we are freed from defining our own Rule instance and have more type safe sugar. The definition corresponds to the pieces above abstracted out and is only a handful of lines.

We do not believe that polymorphic dependencies give any fundamental additional expressive power. What they do is allow greater composition by not having to invent a file name for each thing, by avoiding so many files, and by having far richer keys than simply filenames. We use oracles pervasively in Shake.

If an oracle does not change it does not rerun. This approximately captures the Make pattern of running an action and not updating the output file if it has not changed.

We use oracles pervasively in the GHC build system, fwd ref.

They can also model shared caches.

\subsection{Limiting Parallelism}

When you run -j10 (shakeThreads=10) you are asking the build system to limit computation so it uses no more than ten CPU resources at a time. The CPU is certainly a precious resource, but there are other resource limitations a build system may need to obey:

\begin{enumerate}
\item Some APIs are global in nature, if you run two programs that access the Excel API at the same time things start to fail.
\item Many people have large numbers of CPUs, but only one slow rotating hard drive. If you run ten hard-drive thrashing linkers simultaneously the computer is likely to grind to a halt.
\item Some proprietary software requires licenses, a fixed number of which can be purchased and managed using a license manager. As an example, the Kansas Lava team only have access to 48 licenses for modelsim.
\end{enumerate}

I know of three approaches used by other build systems to obey resource constraints:

\begin{enumerate}
\item Limit the number of CPUs to hit your target - for example, the Lava build system could cap the number of CPUs to the number of licenses. People with 24 CPUs might ask the build system to use only 8, so the linkers do not make their machines unusable (and even then, a link heavy rebuild may still harm interactive performance). This solution wastes CPU resources, leaving CPUs that could be building your code idling.
\item Add locks to suspend jobs that are competing for the shared resource. For example any rule using Excel could take the Excel lock, either a mutex/MVar in some build systems, or creating a file to serve as the lock in make based build systems. Locking can be made to work, but is tricky if you have to fake locks using the file system, and still squanders CPU resources - instead of blocking the CPU should be running another rule.
\item Use dependencies in sequence to ensure that the items running in parallel are serialised.
\end{enumerate}

In Shake the Resource type represents a finite resource, which multiple build rules can use. Resource values are created with newResource and used with withResource. As an example, only one set of calls to the Excel API can occur at one time, therefore Excel is a finite resource of quantity 1. You can write:

\begin{lstlisting}
shake shakeOptions{shakeThreads=2} $ do
    want ["a.xls","b.xls"]
    excel <- newResource "Excel" 1
    "*.xls" *> \out ->
        withResource excel 1 $
            system' "excel" [out,...]
\end{lstlisting}

Now we will never run two copies of excel simultaneously. Moreover, it will never block waiting for excel if there are other rules that could be run.

Fwd ref to ghc-pkg.

\subsection{Tracking File Contents\label{sec:file-contents}}

Build systems run actions on files, skipping the actions if the files have not changed. An important part of that process involves determining if a file has changed. The Make build system uses modification times to impose an ordering on files, but more modern build systems tend to use the modification time as a proxy for the file contents, where any change indicates the contents have changed (e.g. Shake, Ninja). The alternative approach is to compute a hash/digest of the file contents (e.g. SCons, Redo). As of version 0.13, Shake supports both methods, along with three combinations of them - in this post I'll go through the alternatives, and their advantages/disadvantages.

Modification times rely on the file-system updating a timestamp whenever the file contents are written. Modification time is cheap to query. Saving a file afresh will cause the modification time to change, even if the contents do not - as a result touch causes rebuilds. Unfortunately, working with git branches sometimes modifies a file but leaves it with the same contents, which can result in unnecessary rebuilds. We can view the modification time as a surjective function from modification time to file contents.

File digests are computed from the file contents, and accurately reflect if the file contents have changed. There is a remote risk that the file will change without its digest changing, but unless your build system users are actively hostile attackers, that is unlikely. The disadvantage of digests is that they are expensive to compute, requiring a full scan of the file. In particular, after every rule finishes it must scan the file it just built, and on startup the build system must scan all the files. Scanning all the files can cause empty rebuilds to take minutes.

To get the best of both worlds Shake can store the modification time, file size and hash of the contents. After producing a file all information is stored. When checking, first the modification time is checked, and if it matches, the contents have not changed. If the modification time has changed, and the size has changed, then the contents does not match. Only in the case where the modification time has changed but the size has not do we have to compute the actual hash. If after doing that the contents are equal we store a new modification time, so that future checks will be fast. If the contents have changed then the file will likely be rebuilt, and thus will be written afresh with the new hash and modification time.

While a signficant optimisation over always checking file hashes, for certain large files the computation of a hash can still be quite expensive (although almost always cheaper than producing the file). To reduce that problem, Shake has a mode that only digests for source files that are not written by the build system. Generated files (e.g. compiled binaries) tend to be large (expensive to compute digests) and not edited (rarely end up the same), so a poor candidate for digests. The file size check means this restriction is unlikely to make a difference when checking all files, but may have some limited impact when building.

Describe the git pattern. Remove the description of configuration.

\subsection{Design pattern: DSL + escape hatch}

\todo{Probably belongs elsewhere, but don't want to conflict}

As we develop more Shake-based build systems, patterns have started to emerge. Typically 90\% of a build system can be captured in some simple DSL, taking advantage of conventions, and 10\% cannot. As an example, a large build system might build 100 C++ libraries, each with similar flags and file layout, but taking the source files from different directories. It may also minify a Javascript file, and build an installer -- both one-off tasks. Using a fully-powerful system such as Shake, it is possible to engineer robust abstractions, and then define the majority of the build system using only these abstractions. The end result is that most edits to the build system involve only the DSL, and can be performed by a large number of individuals.

After dealing with the DSL, there are usually a few pieces left over, and these can be implemented in Shake, as normal. Thanks to the power of Shake you can interpret the DSL and combine it with the custom pieces. In our experience by providing an \textit{escape hatch} where fully-powerful code an be expressed it removes the temptation to shoehorn more advanced features in the DSL, and thus avoids turning it into an ad-hoc scripting language. Instead, should enough pieces be required in the escape hatch, they can be abstracted in the traditional ways - perhaps even combining two DSLs in one build system.
