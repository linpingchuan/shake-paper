\section{Quick wins: from Make to Shake\label{sec:solutions}}

The GHC build system stumbles into a number of nasty corners of Make. In this
section we reflect on the challenges, and how they can be solved in
our new system. We consider these \empty{unnecessary} complexities --
they are not consequences of our problem domain, merely weaknesses of Make on
large projects. The problems can be divided into those caused by the
Make language (solved using Haskell) and those caused by a lack of expressive
power when describing dependencies (solved using Shake).
After tackling these unnecessary complexities, we show how to structure a
large build system in~\S\ref{sec:abstractions}.

\subsection{Variables}

Make's program state involves a global namespace of mutable string variables that are
spliced into the program. This model naturally causes challenges:

\begin{itemize}
\item Since variables live in a single global namespace, there is limited
encapsulation and implementation hiding.
\item Since variables are strings, arrays and associative maps are typically
encoded using computed variable names, which is error-prone.
\item Since variable references are spliced into the Makefile contents
and interpretted, certain special characters can cause problems --
notably space (which splits lexemes) and colon (which declares rules, but is
also found in Windows drive letters).
\end{itemize}

By using a build system embedded in Haskell, or indeed any other modern programming language,
most of these issues are eliminated. An alternative solution is to generate the Makefile, either using a tool such as Automake or a full programming language. However, a generator cannot interact with the
build system after generation, resulting in problems with dynamic dependencies
(\S\ref{sec:dynamic-deps}).

\subsection{Macros\label{sec:pattern-rule-language}}

Consider the following Make rule:

\begin{lstlisting}
%.o : %.hs
    ghc $HC_OPTS $<
\end{lstlisting}

\noindent It tells Make that object files \lst"*.o" can be produced from Haskell
source files \lst"*.hs" by compiling them with \lst"ghc" command invoked with
\lst"HC_OPTS" arguments. The notation is terse and works well for this example.
Unfortunately, this simple formulation does not scale:

\begin{itemize}
\item What if we want the rule to match \lst"foo.o" and \lst"bar.o", but not
\lst"baz.o"? It is impossible to do any non-trivial computation -- we are forced
to rely on patterns whose expressive power is limited.
\item What if \lst"HC_OPTS" should depends on the file being compiled?
\end{itemize}

The standard Make approach to solve these problems is to use \emph{macros}.
As an example, here is a highly simplified version of the macro from~\S\ref{sec:challenges}:

\begin{lstlisting}
define hs-compile =
$1/$2/build/%.o : $1/$4/%.hs
    ghc $$($1_$2_$3_HC_OPTS) -c $$< -o $$@
endef
\end{lstlisting}

\noindent As before, the rule is responsible for compiling a Haskell source
file into an object file. The arguments to the macro are available as \lst'$1'
to \lst'$4'. We have solved the two problems above, but inelegantly:

\begin{itemize}
\item The restriction to certain directories is solved by using the macro to generate rules, and calling that macro at all relevant matches. We are duplicating the rule to make up for weak pattern matching, and are still quite restricted in what can be expressed.
\item The dependence of the options on the file is solved using a computed variable name, which is dereferenced using \lst'$$(...)' to ensure the value is expanded when the macro is \emph{used}, not when it is \emph{defined}. However, certain variables are present in positions where the value is unavailable when first called, requiring \lst'$$$$(..)' to further delay expansion. Alas, it is far from obvious when extra delaying is required.
\end{itemize}

\noindent Using Shake, the simplest variant looks slightly more complex, because
it must be expressed in Haskell syntax:

\begin{lstlisting}
"*.o" %> \out -> do
    let hs = out -<.> "hs"
    need [hs]
    cmd "ghc" hc_opts hs
\end{lstlisting}
\noindent
However, as the complexity grows, the build system scales properly. Making
\lst"hc_opts" depend on the Haskell file requires the small and obvious change of:

\begin{lstlisting}
cmd "ghc" (hc_opts hs) hs
\end{lstlisting}

\noindent Namely turning \lst'hc_opts' from a constant to a function. To use richer pattern matching we can drop down to a lower-level Shake operation. In Shake \lst"%>" is itself defined in terms of \lst"?>":

\begin{lstlisting}
pat %> act = (pat ?==) ?> act
\end{lstlisting}
\noindent
Wildcard pattern matching is just a special case, and we can use an
arbitrary predicate to exert more precise control over what matches.
In both cases the generality of higher-order functions solves the problem.

\subsection{Generating rules}

In any large-scale build system, there are rules that tell how to build targets,
and then there is a very long list of special cases, listing targets that need
to be treated specially, under certain circumstances, in a congirurable way.
Writing a separate rule for each special case by hand is impractical and
error-prone, hence build rules are typically generated. In Make, this is done by
using macros:

\begin{lstlisting}
WAY_p_HC_OPTS = -static -prof
...
$1_$2_$3_HC_OPTS = $$($1_$2_HC_OPTS) \
#\hspace{34.3mm}#$$(WAY_$3_HC_OPTS) \
#\hspace{34.3mm}#... plus 30 more special cases
\end{lstlisting}

This tells that when building targets with GHC in the \emph{profiling way}
(i.e. with the profiling information enabled), we need to add command line
arguments \lst'-static -prof' to the command line.

\lst'WAY_p_HC_OPTS = -static -prof' is concise, but is inflexible. For example,
if we do not want to pass \lst'-prof' flag when building one particular file, we
will have to either add another component (\lst'WAY_p_file_HC_OPTS'), or
conditionally filter out the \lst'-prof' flag from \lst'HC_OPTS' once it is
constructed.

\todo{\textbf{Andrey}: finilise.}

The question of provenance is particularly important in large multi-author build
systems, but generally not something that is addressed anywhere - one of our key
inovations in \S?. The encapsulation is provided by Haskell modules. The lack of
freedom is provided by strong name binding. The problems related to `:' go away
by manipulating values rather program text.


As we develop more Shake-based build systems, patterns have started to emerge.
Typically 90\% of a build system can be captured in some simple DSL, taking
advantage of conventions, and 10\% cannot. As an example, a large build system
might build 100 C++ libraries, each with similar flags and file layout, but
taking the source files from different directories. It may also minify a
Javascript file, and build an installer -- both one-off tasks. Using a
fully-powerful system such as Shake, it is possible to engineer robust
abstractions, and then define the majority of the build system using only these
abstractions. The end result is that most edits to the build system involve only
the DSL, and can be performed by a large number of individuals.

After dealing with the DSL, there are usually a few pieces left over, and these
can be implemented in Shake, as normal. Thanks to the power of Shake you can
interpret the DSL and combine it with the custom pieces. In our experience by
providing an \emph{escape hatch} where fully-powerful code an be expressed it
removes the temptation to shoehorn more advanced features in the DSL, and thus
avoids turning it into an ad-hoc scripting language. Instead, should enough
pieces be required in the escape hatch, they can be abstracted in the
traditional ways - perhaps even combining two DSLs in one build system.

\subsection{Rules with multiple outputs\label{sec:multiple-outputs}}

Given a Haskell source file \lst'Foo.hs', GHC compilation produces both an
interface file \lst'Foo.hi' and an object file \lst'Foo.o'. The typical way of
expressing multiple outputs in Make is to use two rules, one depending
on the other. For example:

\begin{lstlisting}
%.o : %.hs
    ghc $HC_OPTS $<
#\vspace{-2mm}#
%.hi : %.o ;
\end{lstlisting}
\noindent Here \lst';' is a no-op: it tells Make that an interface file can be
produced simply by depending on the corresponding object file. Alas, this
approach is fragile: if we delete the interface file, but leave the object
file intact, Make will not rerun the \lst'*.o' rule, because the object file is
up-to-date. Consequently, the build system will fail to restore the deleted
interface file.

In Shake we can express this rule directly using the operator \lst'&%>',
which defines a build rule with multiple outputs:

%(it actually turns out to be a
%consequence of the more powerful dependency model):

\begin{lstlisting}
["*.o", "*.hi"] &%> \[o, hi] -> do
    let hs = o -<.> "hs"
    need [hs]
    cmd "ghc" hc_opts hs
\end{lstlisting}

\subsection{Reducing concurrency\label{sec:ghc-pkg-db}}

As discussed in~\S\ref{sec:concurrency-reduction}, it is sometimes necessary to
reduce concurrency in a build system. As an example, GHC packages need to
be registered by invoking the \lst'ghc-pkg' utility. This utility mutates the
global state (package database) and hence at most one package can be registered
at a time, or the database is corrupted.

In Make, the solution is to introduce fake \emph{concurrency
reduction} dependencies. There are 25 GHC packages that require registration,
and in the old build system they all depended on each other in a chain, to
ensure no simultaneous registrations occur. This solution works, but is
fragile (easy to get wrong) and inefficient (reduces available parallelism).

In Shake, the solution is to use the \emph{resources} feature:

\begin{lstlisting}
packageDb <- newResource "package-db" 1

action $ withResource packageDb 1 $ cmd "ghc-pkg" ...
\end{lstlisting}

This snippet declares a global resource named \lst"packageDb" with quantity 1,
then later calls \lst"withResource" asking for a single quantity of the resource before running the
\lst'ghc-pkg' utility. Provided all \lst'ghc-pkg' calls are suitably wrapped,
we will never run two instances simultaneously. Furthermore, thanks to the
availability of functions, we can abstract a function that both executes
\lst'ghc-pkg' and applies the resource.
% Note that build systems already schedule tasks to satisfy the implicit thread
% resource, so having user defined resources is an obvious generalisation.

\subsection{Dynamic dependencies\label{sec:dynamic-deps}}

\todo{\textbf{Andrey}: Rewrite.}

Make, in common with many other build systems, works by
constructing a dependency graph and then executing it. This approach
has some benefits in that it is possible to analyse the graph ahead of
time, but it is limiting in some important ways.  It's common to run
into cases where parts of the dependency graph can only be known after
executing some other parts of the dependency graph.  Some examples of
this that occur in the GHC build system:

\begin{itemize}
\item GHC contains Haskell packages which have metadata specified in
  \lst'.cabal' files. We need to extract the metadata and generate
  \lst'package-data.mk' files to be included into the build system; this
  is done by a Haskell program called \lst'ghc-cabal', which is built by the
  build system. Hence we do not know how to build the packages until we have
  built and run the \lst'ghc-cabal' tool.

  One ``solution'' to this problem is to generate the \lst'.mk'
  files and check them into the repository whenever they change, but
  checking in generated files is ugly and introduces more failure
  cases when the generated files get out of sync.

\item The dependencies of a Haskell source file can be extracted by
  running the compiler, much like using \lst'gcc -M' on a C source
  file.  But the Haskell compiler is one of the things that we are
  building, so we cannot know the dependencies of many of the Haskell
  source files until we have built the stage 1 compiler.

\item Source files processed by the C preprocessor using
  \lst'#include' directives to include other files.  We can only
  know what the dependencies are by running the C preprocessor to
  gather the set of filenames that were included.
\end{itemize}

There are several other cases of such \emph{dynamic dependencies} in the build
system. Indeed, they arise naturally even when building a simple C program,
because the \lst'#include' files for a C source file are not known until the
source file is compiled or analysed by the C compiler, using something like
\lst'gcc -M'. Build systems that have a static dependency graph typically have
special-case support for this; for example, GNU Make will re-read
\lst'Makefiles' that change during building.  In the case of GNU Make,
this works for simple cases, but fails when there are dependencies
between the generated \lst'Makefiles', which arises in more complex cases.

The GHC build system works around this limitation of GNU Make by
dividing the build system into \emph{phases}, where each phase
generates the parts of the build system that are required by
subsequent phases. We managed to reduce the number of phases to
three, by carefully making use of GNU Make's automatic restarting
functionality where possible. However, explicit phases are a terrible
solution for several reasons:

\begin{itemize}
\item Phases reduce concurrency: we cannot start the next phase until
  the previous one is complete.
\item Knowing what targets to put in each phase requires a deep
  understanding of what the generated parts of the build system are
  and their dependencies, and this area of our build system is
  notoriously difficult to work on.  Diagnosing problems is
  particularly hard.
\item Even when doing an incremental build we have to perform all the
  phases, because explicit phases preclude dependency tracking across
  the phase boundary.  This means we have to work around slow
  incremental builds by having an explicit way for the user to say
  that they are sure nothing has changed that would require rebuilding
  the early phases (\lst'make fast').  Obviously this is less than
  ideal.
\end{itemize}

Shake supports dynamic dependencies natively, so these problems just
go away.  The \lst"need" function can introduce new dependencies
\emph{after observing the results of previous dependencies}\footnote{It has been
suggested that the dependency mechanism in Shake should rightly be called
\emph{Monadic dependencies} to contrast with the \emph{Applicative dependencies}
in Make. We agree. In an applicative computation the structure cannot depend on
the values flowing through container. In a monadic computation the structure can
depend on the values.}. For example, when building a Haskell package, we first
\lst"need" the \lst'ghc-cabal' tool, then we run it on the package's \lst'.cabal' file to
extract the package metadata, and then we consult the result to determine what
needs to be done to build the package.

The existence of \lst"need" means that Shake cannot construct the
dependency graph ahead of time, because it doesn't know the full
dependency graph until the build has completed, but this is not a
limitation in practice (while the lack of dynamic dependencies really
\emph{is} a limitation requiring painful workarounds).

% SimonM: I wasn't really sure what this paragraph was trying to say
% While the existence of the \lst"need" fundamentally alters the expressive
% power of Shake, for users it is merely a relaxation of an unnecessary rule
% (that \lst"need" must be the in a rule), so just makes things easier. At the
% build system level it requires many changes, the lack of a static dependency
% graph, termination checking as it executes, the ability to suspend partially
% executed rules etc. Fortunately, as users we do not need to care.

% \subsection{Fine-grain dependencies\label{sec:fine-grain-deps}}
%
% There are many instances where an action depends on a part of a file. As a
% compelling example in GHC, there are many configuration settings provided in a
% file \lst"system.config", which reads:
%
% \begin{lstlisting}
% system-ghc = /usr/bin/ghc
% system-gcc = /usr/bin/gcc
% ...
% \end{lstlisting}
%
% \vspace{-2mm}
% When executing a command we typically depend on only a handful of lines in this
% large configuration file. However, using simple file dependencies, we have to
% depend on the whole file. As a result, we end up rebuilding more than is
% necessary (see~\S\ref{sec:ghc}).
%
% One solution is to create a single file for each setting, but in GHC the whole
% \lst"system.config" file is generated by the \lst'configure' script, which makes
% this challenging. Since a single file is being generated, the next best solution
% is to chop it up into multiple small files, to provide accurate fine-grained
% dependencies.
%
% This approach does not work in Make. We can produce individual
% files, but the individual files must all depend on \lst"system.config", so they
% update appropriately. In the rule to generate the fragments, if we always generate the
% new file, then we do not break the dependencies -- everything still has an
% ultimate dependency on the whole file. If in a rule we chose to avoid generating
% the small file then the file always looks dirty (since its timestamp is older
% than that of \lst"system.config", which Make considers to signify dirty).
%
% Fortunately, Shake supports polymorphic dependencies that solve this problem,
% as discussed in~\S\ref{sec:polymorphic}. This brings dramatic improvements -- on
% real build systems we regularly see build times of a couple of seconds, which
% would have been minutes without this feature (e.g., see~\S\ref{sec:ghc}). This
% feature is also available in \lst'Tup' and \lst'Ninja', although in both cases
% requires explicitly enabling per rule.

% (using \lst'stat' in \lst'Ninja', and \texttt{\^} in Tup).

% Using the same approach in Shake we can simply avoid writing out the small file
% if it has not changed. Shake considers a file to be rebuilt if the rule runs
% successfully, but only considers the file \emph{changed} if its value changed.
% As a result, Shake can start down a build tree and then later avoid that build
% tree. This feature is built into the core of Shake, and means that, unlike
% Make, we can split a single dependency into fine-grained dependencies
% successfully.

% \subsection{Everything is a file}
%
% Once fine grained dependencies are available, they can quickly become
% pervasive. Using a build system based on filenames as keys and files as values
% we effectively reach the global store problem we criticised in \S? (particularly
% if we consider dyanmic dependencies from \S? to be \lst"$" dereferencing!).
% While not critical, Shake supports an Oracle feature, to allow us to make the
% keys and values arbitrary Haskell types, and store them in the main Shake
% database. Thanks to such a technique we can have an oracle per rule we create to
% track changing information, without necessarily doubling the number of files
% present in the build system. As an example:
%
% \begin{lstlisting}
% newtype ConfigKey = ConfigKey String
%     deriving (Show,Typeable,Eq,Hashable,Binary,NFData)
% rules = do
%     addOracle $ \(ConfigKey x) -> do
%         src <- readFile' "system.config"
%         Map.lookup (parseFile src) x
%
%     ... askOracle (ConfigKey x) ...
% \end{lstlisting}
%
% Here we define our own rule of type \lst"ConfigKey" which reads from the
% configuration and stores just that one field. Since this also participates in
% unchanging rules we automatically get rebuild avoidance if the value does not
% change.

\subsection{Real computation\label{sec:real_code}}

Build systems typically spend most of their time calling out to external
processes, e.g. compilers. But sometimes it is useful to replace external processes
with direct functions. As an example, the Make build system used \lst'xargs' to
split command line arguments that exceed a certain size, but that did not work
consistently across OS versions, requiring lots of conditional logic.
Fortunately, with Haskell at our disposal, we can write:

\begin{lstlisting}
-- | @chunksOfSize size strings@ splits a given list of strings
-- into chunks not exceeding @size@ characters. If that is
-- impossible, it uses singleton chunks.
chunksOfSize :: Int -> [String] -> [[String]]
chunksOfSize n = repeatedly $ \xs ->
    let#\,#i = length $ takeWhile#\,#(<=#\,#n) $ scanl1#\,#(+) $ map#\,#length#\,#xs
    in splitAt (max 1 i) xs
\end{lstlisting}

\noindent Writing a small function is easy in Haskell, and even easier to test
(we test this function using QuickCheck). Writing it in \lst'bash' would be infeasible.
Reducing the specific behaviours required from external tools leads to
significantly less cross-platform concerns.

\subsection{Summary}

The unnecessary complexities described in this section have a big impact on
the overall complexity of the build system. The main lessons we have learnt are:

\begin{itemize}
\item Abstraction is a powerful and necessary tool. Lack of good abstraction
mechanisms is a significant cause of the complexity of previous attempts in
Make. Functional programming provides excellent abstractions --
marrying build systems and functional programming works well.
\item Expressive dependencies are important; we use
multiple outputs~\S\ref{sec:multiple-outputs},
resources~\S\ref{sec:ghc-pkg-db} and dynamic dependencies~\S\ref{sec:dynamic-deps}.
While some of these
features are only used in a few places (e.g. resources), their absence would
require pervasive workarounds, and a significant increase in the overall complexity.
\end{itemize}

% \subsection{Abstracting over patterns of dependencies}
%
% \todo{This was moved from Section 5.}
%
% By embedding the build system in Haskell we get access to its rich abstraction
% facilities. Examples:
% \begin{itemize}
%   \item Use general predicates instead of file patterns. For example, several
%   files are built by calling \texttt{genprimopcode}, which can be captured by a
%   single build OR-rule:
%
% \begin{lstlisting}
% [ "autogen/GHC/Prim.hs"
% , "GHC/PrimopWrappers.hs"
% , "*.hs-incl" ] |%> \file -> do ...
% \end{lstlisting}
%
%   \item Build rules with multiple outputs (AND-rules)
%   \item Compute build arguments from target filename
% \end{itemize}
